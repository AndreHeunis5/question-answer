{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bccbb258-3e3f-49b6-86a6-79288546ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.__init__ import OrderedDict\n",
    "import json\n",
    "import re\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from fairseq.models import BaseFairseqModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a578e055-8466-4b78-a572-b2e87d285bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKIDATA_REPLACE_RULES = OrderedDict()\n",
    "WIKIDATA_REPLACE_RULES[\"brack_open\"] = '{'  # \\n\n",
    "WIKIDATA_REPLACE_RULES[\"brack_close\"] = '}'\n",
    "WIKIDATA_REPLACE_RULES[\"attr_open\"] = '('\n",
    "# WIKIDATA_REPLACE_RULES[' \\( '] = '('\n",
    "WIKIDATA_REPLACE_RULES[\"attr_close\"] = ')'\n",
    "# WIKIDATA_REPLACE_RULES[' \\) '] = ')'\n",
    "WIKIDATA_REPLACE_RULES[\"var_\"] = '?'\n",
    "WIKIDATA_REPLACE_RULES[\"sep_dot\"] = '.'  # \\n\n",
    "WIKIDATA_REPLACE_RULES[\"sep_comma\"] = ','  # \\n\n",
    "WIKIDATA_REPLACE_RULES[\"_oba_\"] = 'order by asc'\n",
    "WIKIDATA_REPLACE_RULES[\"_obd_\"] = 'order by desc'\n",
    "WIKIDATA_REPLACE_RULES[\"_grb_\"] = 'group by'\n",
    "WIKIDATA_REPLACE_RULES[\"wd_\"] = 'wd:'\n",
    "WIKIDATA_REPLACE_RULES[\"wdt_\"] = 'wdt:'\n",
    "WIKIDATA_REPLACE_RULES[\"rdfs_\"] = 'rdfs:'\n",
    "WIKIDATA_REPLACE_RULES[\"rdf_\"] = 'rdf:'\n",
    "WIKIDATA_REPLACE_RULES[\"foaf_\"] = 'foaf:'\n",
    "WIKIDATA_REPLACE_RULES[\"p_\"] = 'p:'\n",
    "WIKIDATA_REPLACE_RULES[\"ps_\"] = 'ps:'\n",
    "WIKIDATA_REPLACE_RULES[\"pq_\"] = 'pq:'\n",
    "WIKIDATA_REPLACE_RULES[\"bd_\"] = 'bd:'\n",
    "\n",
    "WIKIDATA_REGEX_REPLACE_RULES = OrderedDict()\n",
    "WIKIDATA_REGEX_REPLACE_RULES[r\"<([\\w\\d_]+)>\"] = r'placeholder_\\1'\n",
    "WIKIDATA_REGEX_REPLACE_RULES[r\"(\\d)[.](\\d)\"] = r\"\\1_dot_\\2\"\n",
    "WIKIDATA_REGEX_REPLACE_RULES[r\"'(.*?)'\"] = r\"apstrph_\\1_apstrph\"\n",
    "WIKIDATA_REGEX_REPLACE_RULES[r\"\\s*([}{)(.,><=])\\s*\"] = r\" \\1 \"\n",
    "WIKIDATA_REGEX_REPLACE_RULES[\">\"] = 'math_gt'\n",
    "WIKIDATA_REGEX_REPLACE_RULES[\"<\"] = 'math_lt'\n",
    "WIKIDATA_REGEX_REPLACE_RULES[\"=\"] = 'math_eq'\n",
    "WIKIDATA_REGEX_REPLACE_RULES[r\"\\s{2,}\"] = ' '\n",
    "#WIKIDATA_REGEX_REPLACE_RULES[r'([,])\\s*\\\"'] = r'\\1 open_quote'\n",
    "#WIKIDATA_REGEX_REPLACE_RULES[r'\\\"\\s*([)])'] = r'\\1 close_quote'\n",
    "\n",
    "WIKIDATA_REGEX_BACK_REPLACE_RULES = OrderedDict()\n",
    "WIKIDATA_REGEX_BACK_REPLACE_RULES[r\"placeholder_(\\w+)\"] = r'<\\1>'\n",
    "WIKIDATA_REGEX_BACK_REPLACE_RULES[r\"(\\d)_dot_(\\d)\"] = r\"\\1.\\2\"\n",
    "WIKIDATA_REGEX_BACK_REPLACE_RULES[r\"apstrph_(.*?)_apstrph\"] = r\"'\\1'\"\n",
    "WIKIDATA_REGEX_BACK_REPLACE_RULES[\"math_gt\"] = ' > '\n",
    "WIKIDATA_REGEX_BACK_REPLACE_RULES[\"math_lt\"] = ' < '\n",
    "WIKIDATA_REGEX_BACK_REPLACE_RULES[\"math_eq\"] = ' = '\n",
    "#WIKIDATA_REGEX_BACK_REPLACE_RULES['open_quote'] = '\\\"'\n",
    "#WIKIDATA_REGEX_BACK_REPLACE_RULES['close_quote'] = '\\\"'\n",
    "\n",
    "WIKIDATA_PREFIXES = OrderedDict()\n",
    "WIKIDATA_PREFIXES[\"wd\"] = \"http://www.wikidata.org/entity/\"\n",
    "WIKIDATA_PREFIXES[\"wdt\"] = \"http://www.wikidata.org/prop/direct/\"\n",
    "WIKIDATA_PREFIXES[\"wiki\"] = \"https://en.wikipedia.org/wiki/\"\n",
    "WIKIDATA_PREFIXES[\"wikibase\"] = \"http://wikiba.se/ontology#\"\n",
    "WIKIDATA_PREFIXES[\"ps\"] = \"http://www.wikidata.org/prop/statement/\"\n",
    "WIKIDATA_PREFIXES[\"pq\"] = \"http://www.wikidata.org/prop/qualifier/\"\n",
    "WIKIDATA_PREFIXES[\"p\"] = \"http://www.wikidata.org/prop/\"\n",
    "WIKIDATA_PREFIXES[\"rdfs\"] = \"http://www.w3.org/2000/01/rdf-schema#\"\n",
    "WIKIDATA_PREFIXES[\"bd\"] = \"http://www.bigdata.com/rdf#\"\n",
    "WIKIDATA_PREFIXES[\"schema\"] = \"http://schema.org/\"\n",
    "WIKIDATA_PREFIXES[\"skos\"] = \"http://www.w3.org/2004/02/skos/core#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b37478-dcbb-41ad-ba6a-55ce5497e61d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rules = WIKIDATA_REPLACE_RULES\n",
    "regex_rules = WIKIDATA_REGEX_REPLACE_RULES\n",
    "regex_back_rules = WIKIDATA_REGEX_BACK_REPLACE_RULES\n",
    "\n",
    "# copied and modified from query_tools.base_tokenizer\n",
    "def encode(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Transform a SPARQL query to a tokenized query string. Compress the query if not compressed.\n",
    "    \"\"\"\n",
    "#     q_string = query.get_query(compressed=True).lower()\n",
    "    q_string = query.lower()\n",
    "    \n",
    "    for pattern, replace in regex_rules.items():  # iterating through keys\n",
    "        q_string = re.sub(pattern, replace, q_string)  # re.sub(rule, key, q_string)\n",
    "        \n",
    "    for key, rule in rules.items():               # iterating through keys\n",
    "        q_string = q_string.replace(rule, key)\n",
    "    return q_string.strip()\n",
    "\n",
    "def decode(query_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Transform a tokenized query string to a SPARQL query. It assumes that the query is tokenize.\n",
    "    Perform correction if needed.\n",
    "    Ej:\n",
    "        tokenize query -> \"select distinct var_uri where brack_open wd_q4072104 wdt_p184 var_uri brack_close\"\n",
    "        query -> \"SELECT DISTINCT ?uri WHERE { wd:q4072104 wdt:p184 ?uri }\"\n",
    "\n",
    "    :param query_string: encoded string query.\n",
    "    :return: Query instance.\n",
    "    \"\"\"\n",
    "    q_string = query_string\n",
    "    for pattern, replace in regex_back_rules.items():  # iterating through keys\n",
    "        q_string = re.sub(pattern, replace, q_string)  # re.sub(rule, key, q_string)\n",
    "    for key, rule in rules.items():  # iterating through keys\n",
    "        q_string = re.sub(key, rule, q_string)  # perform the S&R\n",
    "    return q_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb0f06-92a5-467a-b4e2-81c5d6c3238c",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395bc8af-ce85-43e8-b398-52d262b39c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['questions', 'train', 'valid'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/dataset_lcquad2.json') as df:\n",
    "    lcquad2_data = json.load(df)\n",
    "lcquad2_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06f2dfab-5d9c-495f-b55f-c64377924648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What field does Fernand Maillaud work in?\n",
      "SELECT ?answer WHERE { wd:Q3069252 wdt:P106 ?obj . ?obj wdt:P425 ?answer}\n",
      "[{'label': 'Fernand Maillaud', 'entity': 'wd:Q3069252'}]\n",
      "[{'slot': '<sbj_1>', 'label': 'Fernand Maillaud'}]\n",
      "SELECT ?answer WHERE { <sbj_1> wdt:P106 ?obj . ?obj wdt:P425 ?answer}\n"
     ]
    }
   ],
   "source": [
    "qid = 13007\n",
    "print(lcquad2_data['questions'][qid]['natural_language_question'])\n",
    "print(lcquad2_data['questions'][qid]['query_answer'][0]['sparql_query'])\n",
    "print(lcquad2_data['questions'][qid]['query_answer'][0]['entities'])\n",
    "print(lcquad2_data['questions'][qid]['query_answer'][0]['slots'])\n",
    "print(lcquad2_data['questions'][qid]['query_answer'][0]['sparql_template'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c695dc-3602-4ae7-8a50-403892d903da",
   "metadata": {},
   "outputs": [],
   "source": [
    "select ?value where { <sbj_1> p:p106 ?s . ?s ps:p106 <obj_2> . ?s pq:p101 ?value }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "883c3d2f-f951-4508-abdf-f80fa7be05df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ask where brack_open placeholder_sbj_1 wdt_p106 placeholder_obj_1 brack_close'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode('ASK WHERE { <sbj_1> wdt:P106 <obj_1> }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd76b73-154c-4011-9e3c-456f393c05b4",
   "metadata": {},
   "source": [
    "# Build source and target datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "057ef102-3b1d-4cb4-a97e-3ed4c062ef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['questions', 'train', 'valid'])\n",
      "27706\n"
     ]
    }
   ],
   "source": [
    "with open('data/dataset_lcquad2.json') as df:\n",
    "    lcquad2_data = json.load(df)\n",
    "print(lcquad2_data.keys())\n",
    "print(len(lcquad2_data['questions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e34867-8cef-4f2d-991b-5369aabb5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start, train_end = 0, 400\n",
    "val_start, val_end = 400, 500\n",
    "\n",
    "with open('models/nmt/train.en', 'w+') as nlqen, open('models/nmt/train.sparql', 'w+') as nlqsparql:\n",
    "    for q in lcquad2_data['questions'][train_start:train_end]:\n",
    "        nlqen.write(q['natural_language_question'] + '\\n')\n",
    "        nlqsparql.write(encode(q['query_answer'][0]['sparql_template']) + '\\n')\n",
    "        \n",
    "with open('models/nmt/val.en', 'w+') as nlqen, open('models/nmt/val.sparql', 'w+') as nlqsparql:\n",
    "    for q in lcquad2_data['questions'][val_start:val_end]:\n",
    "        nlqen.write(q['natural_language_question'] + '\\n')\n",
    "        nlqsparql.write(encode(q['query_answer'][0]['sparql_template']) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99168582-3706-477b-8642-e8543e018302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-12 09:55:31 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='models/nmt/data-bin', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='en', srcdict=None, target_lang='sparql', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='models/nmt/train', user_dir=None, validpref='models/nmt/val', workers=1)\n",
      "2021-09-12 09:55:31 | INFO | fairseq_cli.preprocess | [en] Dictionary: 1656 types\n",
      "2021-09-12 09:55:31 | INFO | fairseq_cli.preprocess | [en] models/nmt/train.en: 400 sents, 3816 tokens, 0.0% replaced by <unk>\n",
      "2021-09-12 09:55:31 | INFO | fairseq_cli.preprocess | [en] Dictionary: 1656 types\n",
      "2021-09-12 09:55:31 | INFO | fairseq_cli.preprocess | [en] models/nmt/val.en: 100 sents, 972 tokens, 37.0% replaced by <unk>\n",
      "2021-09-12 09:55:31 | INFO | fairseq_cli.preprocess | [sparql] Dictionary: 128 types\n",
      "2021-09-12 09:55:31 | INFO | fairseq_cli.preprocess | [sparql] models/nmt/train.sparql: 400 sents, 3200 tokens, 0.0% replaced by <unk>\n",
      "2021-09-12 09:55:31 | INFO | fairseq_cli.preprocess | [sparql] Dictionary: 128 types\n",
      "2021-09-12 09:55:31 | INFO | fairseq_cli.preprocess | [sparql] models/nmt/val.sparql: 100 sents, 816 tokens, 2.7% replaced by <unk>\n",
      "2021-09-12 09:55:31 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to models/nmt/data-bin\n"
     ]
    }
   ],
   "source": [
    "!fairseq-preprocess --source-lang en --target-lang sparql --trainpref models/nmt/train --validpref models/nmt/val --destdir models/nmt/data-bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ccf7841-5cfd-4bc1-9751-95dc90e99b51",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-12 09:55:53 | INFO | fairseq_cli.train | Namespace(adam_betas='(0.9, 0.999)', adam_eps=1e-08, all_gather_list_size=16384, arch='fconv_wmt_en_de', batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='models/nmt/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention='True', decoder_embed_dim=768, decoder_embed_path=None, decoder_layers='[(512, 3)] * 9 + [(1024, 3)] * 4 + [(2048, 1)] * 2', decoder_out_embed_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=0, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.2, empty_cache_freq=0, encoder_embed_dim=768, encoder_embed_path=None, encoder_layers='[(512, 3)] * 9 + [(1024, 3)] * 4 + [(2048, 1)] * 2', eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=50, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='simple', log_interval=100, lr=[0.001], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=500, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='fairseq_fconv_wmt_en_de', save_interval=100, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='en', stop_time_hours=0, target_lang='sparql', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, weight_decay=0.0, zero_sharding='none')\n",
      "2021-09-12 09:55:53 | INFO | fairseq.tasks.translation | [en] dictionary: 1656 types\n",
      "2021-09-12 09:55:53 | INFO | fairseq.tasks.translation | [sparql] dictionary: 128 types\n",
      "2021-09-12 09:55:53 | INFO | fairseq.data.data_utils | loaded 100 examples from: models/nmt/data-bin/valid.en-sparql.en\n",
      "2021-09-12 09:55:53 | INFO | fairseq.data.data_utils | loaded 100 examples from: models/nmt/data-bin/valid.en-sparql.sparql\n",
      "2021-09-12 09:55:53 | INFO | fairseq.tasks.translation | models/nmt/data-bin valid en-sparql 100 examples\n",
      "2021-09-12 09:55:55 | INFO | fairseq_cli.train | FConvModel(\n",
      "  (encoder): FConvEncoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(1656, 768, padding_idx=1)\n",
      "    (embed_positions): LearnedPositionalEmbedding(1024, 768, padding_idx=1)\n",
      "    (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (projections): ModuleList(\n",
      "      (0): None\n",
      "      (1): None\n",
      "      (2): None\n",
      "      (3): None\n",
      "      (4): None\n",
      "      (5): None\n",
      "      (6): None\n",
      "      (7): None\n",
      "      (8): None\n",
      "      (9): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (10): None\n",
      "      (11): None\n",
      "      (12): None\n",
      "      (13): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "      (14): None\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
      "      (1): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
      "      (2): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
      "      (3): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
      "      (4): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
      "      (5): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
      "      (6): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
      "      (7): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
      "      (8): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
      "      (9): ConvTBC(512, 2048, kernel_size=(3,), padding=(1,))\n",
      "      (10): ConvTBC(1024, 2048, kernel_size=(3,), padding=(1,))\n",
      "      (11): ConvTBC(1024, 2048, kernel_size=(3,), padding=(1,))\n",
      "      (12): ConvTBC(1024, 2048, kernel_size=(3,), padding=(1,))\n",
      "      (13): ConvTBC(1024, 4096, kernel_size=(1,), padding=(0,))\n",
      "      (14): ConvTBC(2048, 4096, kernel_size=(1,), padding=(0,))\n",
      "    )\n",
      "    (fc2): Linear(in_features=2048, out_features=768, bias=True)\n",
      "  )\n",
      "  (decoder): FConvDecoder(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(128, 768, padding_idx=1)\n",
      "    (embed_positions): LearnedPositionalEmbedding(1024, 768, padding_idx=1)\n",
      "    (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (projections): ModuleList(\n",
      "      (0): None\n",
      "      (1): None\n",
      "      (2): None\n",
      "      (3): None\n",
      "      (4): None\n",
      "      (5): None\n",
      "      (6): None\n",
      "      (7): None\n",
      "      (8): None\n",
      "      (9): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (10): None\n",
      "      (11): None\n",
      "      (12): None\n",
      "      (13): Linear(in_features=1024, out_features=2048, bias=True)\n",
      "      (14): None\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
      "      (1): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
      "      (2): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
      "      (3): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
      "      (4): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
      "      (5): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
      "      (6): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
      "      (7): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
      "      (8): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
      "      (9): LinearizedConvolution(512, 2048, kernel_size=(3,), padding=(2,))\n",
      "      (10): LinearizedConvolution(1024, 2048, kernel_size=(3,), padding=(2,))\n",
      "      (11): LinearizedConvolution(1024, 2048, kernel_size=(3,), padding=(2,))\n",
      "      (12): LinearizedConvolution(1024, 2048, kernel_size=(3,), padding=(2,))\n",
      "      (13): LinearizedConvolution(1024, 4096, kernel_size=(1,), padding=(0,))\n",
      "      (14): LinearizedConvolution(2048, 4096, kernel_size=(1,), padding=(0,))\n",
      "    )\n",
      "    (attention): ModuleList(\n",
      "      (0): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
      "      )\n",
      "      (1): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
      "      )\n",
      "      (2): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
      "      )\n",
      "      (3): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
      "      )\n",
      "      (4): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
      "      )\n",
      "      (5): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
      "      )\n",
      "      (6): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
      "      )\n",
      "      (7): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
      "      )\n",
      "      (8): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
      "      )\n",
      "      (9): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=1024, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=1024, bias=True)\n",
      "      )\n",
      "      (10): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=1024, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=1024, bias=True)\n",
      "      )\n",
      "      (11): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=1024, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=1024, bias=True)\n",
      "      )\n",
      "      (12): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=1024, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=1024, bias=True)\n",
      "      )\n",
      "      (13): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=2048, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=2048, bias=True)\n",
      "      )\n",
      "      (14): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=2048, out_features=768, bias=True)\n",
      "        (out_projection): Linear(in_features=768, out_features=2048, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (fc3): Linear(in_features=512, out_features=128, bias=True)\n",
      "  )\n",
      ")\n",
      "2021-09-12 09:55:55 | INFO | fairseq_cli.train | task: translation (TranslationTask)\n",
      "2021-09-12 09:55:55 | INFO | fairseq_cli.train | model: fconv_wmt_en_de (FConvModel)\n",
      "2021-09-12 09:55:55 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)\n",
      "2021-09-12 09:55:55 | INFO | fairseq_cli.train | num. model params: 129005824 (num. trained: 129005824)\n",
      "2021-09-12 09:55:55 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2021-09-12 09:55:55 | INFO | fairseq_cli.train | max tokens per GPU = 4000 and max sentences per GPU = None\n",
      "2021-09-12 09:55:55 | INFO | fairseq.trainer | no existing checkpoint found fairseq_fconv_wmt_en_de/checkpoint_last.pt\n",
      "2021-09-12 09:55:55 | INFO | fairseq.trainer | loading train data for epoch 1\n",
      "2021-09-12 09:55:55 | INFO | fairseq.data.data_utils | loaded 400 examples from: models/nmt/data-bin/train.en-sparql.en\n",
      "2021-09-12 09:55:55 | INFO | fairseq.data.data_utils | loaded 400 examples from: models/nmt/data-bin/train.en-sparql.sparql\n",
      "2021-09-12 09:55:55 | INFO | fairseq.tasks.translation | models/nmt/data-bin train en-sparql 400 examples\n",
      "2021-09-12 09:55:55 | INFO | fairseq.trainer | begin training epoch 1\n",
      "/Users/andreheunis/python_projects/KBQA/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:949: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "2021-09-12 09:56:40 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2021-09-12 09:56:48 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 352.411 | nll_loss 299.756 | ppl inf | wps 0 | wpb 816 | bsz 100 | num_updates 2\n",
      "2021-09-12 09:56:48 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
      "2021-09-12 09:56:48 | INFO | train | epoch 001 | loss 4.872 | nll_loss 4.535 | ppl 23.18 | wps 65.5 | ups 0.02 | wpb 1600 | bsz 200 | num_updates 2 | lr 0.001 | gnorm 2.062 | clip 100 | train_wall 45 | wall 53\n",
      "2021-09-12 09:56:48 | INFO | fairseq.trainer | begin training epoch 2\n",
      "2021-09-12 09:58:02 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2021-09-12 09:58:10 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 96.823 | nll_loss 74.691 | ppl 3.05035e+22 | wps 0 | wpb 816 | bsz 100 | num_updates 4\n",
      "2021-09-12 09:58:10 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
      "2021-09-12 09:58:10 | INFO | train | epoch 002 | loss 443.969 | nll_loss 377.577 | ppl inf | wps 39.2 | ups 0.02 | wpb 1600 | bsz 200 | num_updates 4 | lr 0.001 | gnorm 6271.14 | clip 100 | train_wall 73 | wall 135\n",
      "2021-09-12 09:58:10 | INFO | fairseq.trainer | begin training epoch 3\n",
      "2021-09-12 09:59:15 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2021-09-12 09:59:23 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 1398.86 | nll_loss 1507.41 | ppl inf | wps 0 | wpb 816 | bsz 100 | num_updates 6\n",
      "2021-09-12 09:59:23 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
      "2021-09-12 09:59:23 | INFO | train | epoch 003 | loss 175.164 | nll_loss 173.365 | ppl inf | wps 43.8 | ups 0.03 | wpb 1600 | bsz 200 | num_updates 6 | lr 0.001 | gnorm 199119 | clip 100 | train_wall 64 | wall 208\n",
      "2021-09-12 09:59:23 | INFO | fairseq.trainer | begin training epoch 4\n",
      "2021-09-12 10:00:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "2021-09-12 10:00:45 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4139.72 | nll_loss 4415.02 | ppl inf | wps 0 | wpb 816 | bsz 100 | num_updates 8\n",
      "2021-09-12 10:00:45 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
      "2021-09-12 10:00:45 | INFO | train | epoch 004 | loss 1473.62 | nll_loss 1581.92 | ppl inf | wps 39 | ups 0.02 | wpb 1600 | bsz 200 | num_updates 8 | lr 0.001 | gnorm 2.38091e+06 | clip 100 | train_wall 73 | wall 290\n",
      "2021-09-12 10:00:45 | INFO | fairseq.trainer | begin training epoch 5\n",
      "2021-09-12 10:01:50 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n"
     ]
    }
   ],
   "source": [
    "# --valid-subset valid,test\n",
    "!fairseq-train models/nmt/data-bin -s en -t sparql \\\n",
    "--lr 0.001 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
    "--criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "--arch fconv_wmt_en_de --lr-scheduler fixed --force-anneal 50 \\\n",
    "--max-epoch 500 --save-interval 100 \\\n",
    "--save-dir fairseq_fconv_wmt_en_de \\\n",
    "--optimizer adam \\\n",
    "--log-format simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d47c2f-da3a-4dd6-9351-e13fd5bdf115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8af9e-39ae-40ff-9caf-5a1538f988b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babdb065-96d2-4989-8cb7-6782fad77cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86605275-a4fe-48e0-a6ea-0f3162729c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51345c-2b90-41ef-b5a5-ec87147c9a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4bc503-76dc-4ffa-8196-6aaf56cfbfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f413901-c682-48e2-be09-968d0bd0a3d4",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d47ac7-a503-43e0-88d6-0dd60053e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = BaseFairseqModel.from_pretrained('models/nmt/', checkpoint_file='checkpoint_best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb94b71b-21db-410a-89a6-3b628d8542b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeneratorHubInterface(\n",
       "  (models): ModuleList(\n",
       "    (0): FConvModel(\n",
       "      (encoder): FConvEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(6416, 768, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1024, 768, padding_idx=1)\n",
       "        (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
       "        (projections): ModuleList(\n",
       "          (0): None\n",
       "          (1): None\n",
       "          (2): None\n",
       "          (3): None\n",
       "          (4): None\n",
       "          (5): None\n",
       "          (6): None\n",
       "          (7): None\n",
       "          (8): None\n",
       "          (9): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (10): None\n",
       "          (11): None\n",
       "          (12): None\n",
       "          (13): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "          (14): None\n",
       "        )\n",
       "        (convolutions): ModuleList(\n",
       "          (0): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
       "          (1): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
       "          (2): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
       "          (3): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
       "          (4): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
       "          (5): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
       "          (6): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
       "          (7): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
       "          (8): ConvTBC(512, 1024, kernel_size=(3,), padding=(1,))\n",
       "          (9): ConvTBC(512, 2048, kernel_size=(3,), padding=(1,))\n",
       "          (10): ConvTBC(1024, 2048, kernel_size=(3,), padding=(1,))\n",
       "          (11): ConvTBC(1024, 2048, kernel_size=(3,), padding=(1,))\n",
       "          (12): ConvTBC(1024, 2048, kernel_size=(3,), padding=(1,))\n",
       "          (13): ConvTBC(1024, 4096, kernel_size=(1,), padding=(0,))\n",
       "          (14): ConvTBC(2048, 4096, kernel_size=(1,), padding=(0,))\n",
       "        )\n",
       "        (fc2): Linear(in_features=2048, out_features=768, bias=True)\n",
       "      )\n",
       "      (decoder): FConvDecoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(4416, 768, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(1024, 768, padding_idx=1)\n",
       "        (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
       "        (projections): ModuleList(\n",
       "          (0): None\n",
       "          (1): None\n",
       "          (2): None\n",
       "          (3): None\n",
       "          (4): None\n",
       "          (5): None\n",
       "          (6): None\n",
       "          (7): None\n",
       "          (8): None\n",
       "          (9): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (10): None\n",
       "          (11): None\n",
       "          (12): None\n",
       "          (13): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "          (14): None\n",
       "        )\n",
       "        (convolutions): ModuleList(\n",
       "          (0): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
       "          (1): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
       "          (2): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
       "          (3): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
       "          (4): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
       "          (5): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
       "          (6): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
       "          (7): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
       "          (8): LinearizedConvolution(512, 1024, kernel_size=(3,), padding=(2,))\n",
       "          (9): LinearizedConvolution(512, 2048, kernel_size=(3,), padding=(2,))\n",
       "          (10): LinearizedConvolution(1024, 2048, kernel_size=(3,), padding=(2,))\n",
       "          (11): LinearizedConvolution(1024, 2048, kernel_size=(3,), padding=(2,))\n",
       "          (12): LinearizedConvolution(1024, 2048, kernel_size=(3,), padding=(2,))\n",
       "          (13): LinearizedConvolution(1024, 4096, kernel_size=(1,), padding=(0,))\n",
       "          (14): LinearizedConvolution(2048, 4096, kernel_size=(1,), padding=(0,))\n",
       "        )\n",
       "        (attention): ModuleList(\n",
       "          (0): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (1): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (2): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (3): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (4): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (5): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (6): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (7): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (8): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=512, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (9): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (10): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (11): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (12): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=1024, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=1024, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (13): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=2048, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=2048, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "          (14): AttentionLayer(\n",
       "            (in_projection): Linear(in_features=2048, out_features=768, bias=True)\n",
       "            (out_projection): Linear(in_features=768, out_features=2048, bias=True)\n",
       "            (bmm): BeamableMM()\n",
       "          )\n",
       "        )\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (fc3): Linear(in_features=512, out_features=4416, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c00ec9b-2ae0-4d0e-86c4-d62eddf1cdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreheunis/python_projects/KBQA/venv/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SELECT DISTINCT var_uri WHERE brack_open <dbr_Grey_Goose_ attr_open soft_drink attr_close math_gt <dbp_origin> var_uri brack_close'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.translate('Did Alexander Hamilton practice law?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adb657ac-d207-47f8-b2df-7e3c4af9ac5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT DISTINCT var_uri WHERE brack_open <dbr_Grey_Goose_ attr_open song attr_close math_gt <dbp_artist> var_uri brack_close'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator.translate('Is Harrelson the real family name of Woody Harrelson?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc29eec-42e0-4b2d-955d-081da7a9f1f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11983f65-63ca-40a9-8efa-241e9c786c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4db186-97b7-402c-be9f-1378a9ef32f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42133404-5341-49b6-bfca-3484323a99d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb122bf-db55-4dc6-b86e-3ea8a96b3ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef202553-6448-476a-9236-c09f55b7f66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
